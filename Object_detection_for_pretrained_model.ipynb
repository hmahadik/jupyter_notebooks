{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object detection for pretrained model",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmahadik/jupyter_notebooks/blob/master/Object_detection_for_pretrained_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "KUu4vOt5zI9d"
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If7KUFtdEko1"
      },
      "source": [
        "#@title\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxmDMK4yupqg"
      },
      "source": [
        "# Object detection\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "This Colab demonstrates use of a TF-Hub module trained to perform object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfiqHNv9HqSO"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssZlGclyYCrB"
      },
      "source": [
        "#@title All installs { display-mode: \"form\" }\n",
        "# Currently %tensorflow_version 2.x installs beta1, which doesn't work here.\n",
        "# %tensorflow_version can likely be used after 2.0rc0  \n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!git clone --quiet https://github.com/zamblauskas/oidv4-toolkit-tfrecord-generator.git\n",
        "!git clone --quiet https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "!pip3 install -q -r OIDv4_ToolKit/requirements.txt\n",
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Imports and function definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cPY9Ou4sWs_"
      },
      "source": [
        "#@title All imports { display-mode: \"form\" }\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For annotation functions\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import object_detection_evaluation\n",
        "from object_detection.utils import per_image_evaluation\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by07kjrrWnKx"
      },
      "source": [
        "## All directories (Set by yourself)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaZdoumJwGxa"
      },
      "source": [
        "#@title ##Fill in part\n",
        "#for the classes we actually use\n",
        "#Please only enter the classes in mscoco dataset\n",
        "#classes_set = ['Box', 'Man', 'Suitcase', 'Handbag', 'Backpack']\n",
        "#for the classes we are looking for\n",
        "#@markdown ###Please choose from mscoco dataset for classes\n",
        "classes_set2 = ['Person', 'Suitcase', 'Handbag', 'Backpack'] #@param {type:\"raw\"}\n",
        "#@markdown ---\n",
        "#number of images for training\n",
        "num_train = 150 #@param {type:\"integer\"}\n",
        "num_val = 50 #@param {type:\"integer\"}\n",
        "\n",
        "#name of pipeline file\n",
        "pipeline_file = 'ssd_mobilenet_v2_coco.config' #@param {type:\"string\"}\n",
        "label_file_name = 'oid_bbox_trainable_label_map.pbtxt' #@param {type:\"string\"}\n",
        "#where the model is saved\n",
        "MODEL_DIR = '/content/model_trained' #@param {type:\"string\"}\n",
        "#number of steps\n",
        "TRAIN_STEP = 50000 #@param {type:\"integer\"}\n",
        "EVAL_STEP = 50 #@param {type:\"integer\"}\n",
        "\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "num_steps = 50000 #@param {type:\"integer\"}\n",
        "\n",
        "load_all_ckpt = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8) #@param {type:\"raw\"}\n",
        "\n",
        "MODEL_NAME_CHECK = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03' #@param ['ssd_mobilenet_v1_coco_2017_11_17', 'ssd_mobilenet_v2_coco_2018_03_29', 'faster_rcnn_resnet101_coco_2018_01_28','ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'] {type:\"string\"}\n",
        "MODEL_NAME_TRAIN = 'ssd_mobilenet_v2_coco_2018_03_29' #@param {type:\"string\"}\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/' #@param {type:\"string\"}\n",
        "\n",
        "output_freeze_directory = '/content/out_graph/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp1x4o94f5Yb"
      },
      "source": [
        "#@title Other directories { display-mode: \"form\" }\n",
        "\n",
        "num_classes = len(classes_set2)\n",
        "class_description_path = '/content/OID/csv_folder/class-descriptions-boxable.csv'\n",
        "annotation_path_train = '/content/OID/csv_folder/train-annotations-bbox.csv'\n",
        "annotation_path_val = '/content/OID/csv_folder/validation-annotations-bbox.csv'\n",
        "fail_dir = '/content/failed_image'\n",
        "model_dir = '/content/model_trained'\n",
        "class_dir = '/content/OIDv4_ToolKit/classes.txt'\n",
        "tf_dir = '/content/tfrecord'\n",
        "\n",
        "val_record_fname = os.path.join(tf_dir, 'val.tfrecord')\n",
        "train_record_fname = os.path.join(tf_dir, 'train.tfrecord')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwFJ5q6JHwcd"
      },
      "source": [
        "## Download images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSR24q4XVt1"
      },
      "source": [
        "#@title Download images from OID! { display-mode: \"form\" }\n",
        "\n",
        "seperator = ' '\n",
        "print(seperator.join(classes_set2))\n",
        "class_str = seperator.join(classes_set2)\n",
        "seperator_ul = '_'\n",
        "class_str_ul = seperator_ul.join(classes_set2)\n",
        "\n",
        "image_dir_train = '/content/OID/Dataset/train/'+class_str_ul+'/'\n",
        "image_dir_val = '/content/OID/Dataset/validation/'+class_str_ul+'/'\n",
        "%cd /content/\n",
        "!python3 OIDv4_ToolKit/main.py downloader -y --classes {class_str} --type_csv train --limit {num_train} --multiclasses 1\n",
        "!python3 OIDv4_ToolKit/main.py downloader -y --classes {class_str} --type_csv validation --limit {num_val} --multiclasses 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlA3CftFpRiW"
      },
      "source": [
        "## Helper functions for downloading images and for visualization.\n",
        "\n",
        "Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg0BGy2okhVA"
      },
      "source": [
        "#@title make_dir { display-mode: \"form\" }\n",
        "def make_dir(dir_name):\n",
        "    try:\n",
        "        os.mkdir(dir_name)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % dir_name)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % dir_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTkSSAybjAtU"
      },
      "source": [
        "#@title Read annotations. { display-mode: \"form\" }\n",
        "#read annotation for certain image from annotation file\n",
        "def read_annotation(classes_set, \n",
        "                    class_description_path, \n",
        "                    annotation_path, \n",
        "                    image_dir):\n",
        "  \n",
        "  classes = list(filter(None, classes_set))\n",
        "  classes = {name: idx + 1 for idx, name in enumerate(classes)}\n",
        "  class_descriptions = {row[0]: row[1] for _, row in pd.read_csv(class_description_path, header=None).iterrows()}\n",
        "  annotations = pd.read_csv(annotation_path)\n",
        "  annotations['LabelName'] = annotations['LabelName'].map(lambda n: class_descriptions[n])\n",
        "  annotations = annotations.groupby('ImageID')             \n",
        "  #images = tf.io.gfile.glob(image_dir + '/*.jpg')\n",
        "  images = tf.io.gfile.glob(os.path.join(image_dir, '*.jpg'))\n",
        "  images = map(lambda i: (os.path.basename(i).split('.jpg')[0], i), images)\n",
        "  images = dict(images)           \n",
        "\n",
        "  image_pathes = []               \n",
        "  xmins = []\n",
        "  xmaxs = []\n",
        "  ymins = []\n",
        "  ymaxs = []\n",
        "  boxes = []\n",
        "  classes_text = []\n",
        "  classes_int = []  \n",
        "  is_group = []\n",
        "  is_difficult = []\n",
        "  count = 0               \n",
        "  for image_id, path in images.items():\n",
        "        img_width, img_height = Image.open(path).size\n",
        "        #img_data = tf.gfile.GFile(path, 'rb').read()\n",
        "        image_annotations = annotations.get_group(image_id)\n",
        "        for _, row in image_annotations.loc[image_annotations['LabelName'].isin(classes.keys())].iterrows():\n",
        "            image_pathes.append(row['ImageID'])\n",
        "            xmins.append(row['XMin'])\n",
        "            xmaxs.append(row['XMax'])\n",
        "            ymins.append(row['YMin'])\n",
        "            ymaxs.append(row['YMax'])\n",
        "            classes_text.append(row['LabelName'].encode('utf8'))\n",
        "            classes_int.append(classes[row['LabelName']])\n",
        "            is_group.append(row['IsGroupOf'])\n",
        "            is_difficult.append(0)\n",
        "  boxes = np.concatenate(([xmins], [ymins], [xmaxs], [ymaxs]),0)\n",
        "  boxes = np.transpose(boxes)\n",
        "  #image_pathes = np.transpose(image_pathes)\n",
        "  classes_text = np.array(classes_text)\n",
        "  classes_int = np.array(classes_int)\n",
        "  is_group = np.array(is_group)\n",
        "  is_difficult = np.array(is_difficult)\n",
        "  #boxes = [np.reshape(xmins, (-1, 1)),np.reshape(xmaxs, (-1, 1)),np.reshape(ymins, (-1, 1)),np.reshape(ymaxs, (-1, 1))]\n",
        "  return image_pathes, boxes, classes_text, classes_int, is_group, is_difficult\n",
        "                 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnMJevDnmram"
      },
      "source": [
        "#@title Write tfrecord { display-mode: \"form\" }\n",
        "def write_tf(classes_file, output_file, class_descriptions_file, annotations_file, image_dir):\n",
        "    classes = list(filter(None, open(classes_file).read().split('\\n')))\n",
        "    classes = {name: idx + 1 for idx, name in enumerate(classes)}\n",
        "    #print(f'Classes: {classes}')\n",
        "    #print(f'Classes: {classes}')\n",
        "    class_descriptions = {row[0]: row[1] for _, row in pd.read_csv(class_descriptions_file, header=None).iterrows()}\n",
        "\n",
        "    annotations = pd.read_csv(annotations_file)\n",
        "    annotations['LabelName'] = annotations['LabelName'].map(lambda n: class_descriptions[n])\n",
        "    annotations = annotations.groupby('ImageID')\n",
        "\n",
        "    images = tf.io.gfile.glob(image_dir + '*.jpg')\n",
        "    images = map(lambda i: (os.path.basename(i).split('.jpg')[0], i), images)\n",
        "    images = dict(images)\n",
        "    writer = tf.io.TFRecordWriter(output_file)\n",
        "    for image_id, path in images.items():\n",
        "        #print(image_id)\n",
        "        img_width, img_height = Image.open(path).size\n",
        "        img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "\n",
        "        xmins = []\n",
        "        xmaxs = []\n",
        "        ymins = []\n",
        "        ymaxs = []\n",
        "        classes_text = []\n",
        "        classes_int = []\n",
        "\n",
        "        image_annotations = annotations.get_group(image_id)\n",
        "        for _, row in image_annotations.loc[image_annotations['LabelName'].isin(classes.keys())].iterrows():\n",
        "            xmins.append(row['XMin'])\n",
        "            xmaxs.append(row['XMax'])\n",
        "            ymins.append(row['YMin'])\n",
        "            ymaxs.append(row['YMax'])\n",
        "            classes_text.append(row['LabelName'].encode('utf8'))\n",
        "            classes_int.append(classes[row['LabelName']])\n",
        "\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "            'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[img_height])),\n",
        "            'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[img_width])),\n",
        "            'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_id.encode('utf8')])),\n",
        "            'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_id.encode('utf8')])),\n",
        "            'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_data])),\n",
        "            'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'jpg'])),\n",
        "            'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
        "            'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
        "            'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
        "            'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
        "            'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "            'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes_int))\n",
        "        }))\n",
        "\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "        #print('.', end='')\n",
        "    writer.close()\n",
        "    print(\" done\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MAmsjIwLtfa"
      },
      "source": [
        "#@title load_image_into_numpy_array { display-mode: \"form\" }\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  try:\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "  except:\n",
        "    return []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JoS3T9_Gi4Z"
      },
      "source": [
        "#@title run_inference_for_single_image { display-mode: \"form\" }\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "      \n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka81fSobYNIZ"
      },
      "source": [
        "#@title run_filter_on_dir2 { display-mode: \"form\" }\n",
        "\n",
        "def run_filter_on_dir2(img_dir, annotation_path):\n",
        "  g_pathes_all, g_boxes_all, g_classes_all, g_classes_int_all, is_g_all, is_d_all = read_annotation(classes_set2, class_description_path, annotation_path, img_dir)\n",
        "  img_name_list = [x.split('.')[0] for x in os.listdir(img_dir)]\n",
        "  for img_name in img_name_list:\n",
        "    if img_name == 'Label':\n",
        "        continue\n",
        "    img_path_curr = os.path.join(img_dir, img_name)+'.jpg'\n",
        "    image = Image.open(img_path_curr)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    if image_np == []:\n",
        "      img_path_new = os.path.join(fail_dir, img_name)+'.jpg'\n",
        "      shutil.move(img_path_curr, img_path_new) \n",
        "      continue\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "\n",
        "    idx_new = []\n",
        "    for count, class_int in enumerate(output_dict['detection_classes']):\n",
        "      #print(class_int)\n",
        "      class_name = list(label_dict_coco.keys())[list(label_dict_coco.values()).index(class_int)]\n",
        "      if class_name in label_dict.keys():\n",
        "        #print(class_name)\n",
        "        idx_new.append(count)\n",
        "        output_dict['detection_classes'][count] = label_dict[class_name]\n",
        "\n",
        "    for item in output_dict:\n",
        "      if item == 'num_detections':\n",
        "        continue\n",
        "      output_dict[item] = output_dict[item][idx_new]\n",
        "    d_boxes = np.copy(output_dict[\"detection_boxes\"])\n",
        "    #d_boxes_copy = output_dict[\"detection_boxes\"]\n",
        "    #print(output_dict[\"detection_boxes\"])\n",
        "    #print(d_boxes)\n",
        "    #format to match the annotation \n",
        "    temp = np.copy(d_boxes[:, 0])\n",
        "    d_boxes[:, 0] = d_boxes[:, 1]\n",
        "    d_boxes[:, 1] = temp\n",
        "    temp = np.copy(d_boxes[:, 2])\n",
        "    d_boxes[:, 2] = d_boxes[:, 3]\n",
        "    d_boxes[:, 3] = temp\n",
        "    d_scores = output_dict[\"detection_scores\"]\n",
        "    d_class_int = output_dict[\"detection_classes\"]\n",
        "    idx_new = []\n",
        "    for i in range(len(g_pathes_all)):\n",
        "      if g_pathes_all[i] == img_name:\n",
        "        idx_new.append(i)\n",
        "    g_boxes = np.array(g_boxes_all[idx_new])\n",
        "    g_classes = np.array(g_classes_all[idx_new])\n",
        "    is_g = np.array(is_g_all[idx_new])\n",
        "    is_d = np.array(is_d_all[idx_new])\n",
        "    g_classes_int = np.array(g_classes_int_all[idx_new])\n",
        "    is_g = np.array(is_g,dtype=bool)\n",
        "    evaluator = per_image_evaluation.PerImageEvaluation(num_classes+1)  \n",
        "    #print(d_class_int)\n",
        "    rearrange_class_idx(classes, label_dict, d_class_int)\n",
        "    #print(d_class_int)\n",
        "    #print(g_classes_int)\n",
        "    scores, tp_fp_labels, is_class_correctly_detected_in_image = evaluator.compute_object_detection_metrics(d_boxes, d_scores, d_class_int, g_boxes, g_classes_int, is_d, is_g)\n",
        "\n",
        "    detected_right_num = 0\n",
        "    for item_array in tp_fp_labels:\n",
        "      detected_right_num = detected_right_num+sum(item_array) \n",
        "    num_ground_truth = np.shape(g_boxes)[0]\n",
        "    print(detected_right_num)\n",
        "    print(num_ground_truth)  \n",
        "    if detected_right_num == num_ground_truth and detected_right_num != 0:\n",
        "      print(\"image \" + img_name + \" passed!\")\n",
        "    else:\n",
        "      print(\"image \" + img_name + \" failed! Image Removed!\")\n",
        "      img_path_new = os.path.join(fail_dir, img_name)+'.jpg'\n",
        "      shutil.move(img_path_curr, img_path_new) \n",
        "\n",
        "    # Visualization of the results of a detection.\n",
        "'''    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        #d_boxes_copy,\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Kjewea-T8W"
      },
      "source": [
        "##Using pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZw6j8nF-yXr"
      },
      "source": [
        "# What model to download.\n",
        "\n",
        "MODEL_FILE = MODEL_NAME_CHECK + '.tar.gz'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME_CHECK + '/frozen_inference_graph.pb'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwzz6DrQgh1Q"
      },
      "source": [
        "import re\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "PATH_TO_LABELS = os.path.join('/content/object_detection/data/', label_file_name)\n",
        "dst_label = os.path.join('/content/', label_file_name)\n",
        "copyfile(PATH_TO_LABELS, dst_label)\n",
        "\n",
        "label_map_int = label_map_util.load_labelmap(dst_label)\n",
        "for item in label_map_int.item:\n",
        "    if item.display_name not in classes_set2:\n",
        "        item.Clear()\n",
        "\n",
        "\n",
        "input_txt = str(label_map_int)\n",
        "input_txt = input_txt.replace(\"item {\\n}\\n\", \"\")\n",
        "#print(input_txt)\n",
        "with open(dst_label, 'w') as f:\n",
        "    s = f.write(input_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGj16PHyBBJE"
      },
      "source": [
        "import six.moves.urllib as urllib\n",
        "import tarfile\n",
        "%cd /content/\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdQZHB_BBw8"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfCbpMSeJ5Um"
      },
      "source": [
        "label_dict = label_map_util.get_label_map_dict(dst_label, use_display_name=True)\n",
        "label_dict = {k.lower():v for k, v in label_dict.items()}\n",
        "print(label_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWQOKmIMjNSn"
      },
      "source": [
        "label_map = label_map_util.load_labelmap(dst_label)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_coco_path = '/content/object_detection/data/mscoco_label_map.pbtxt'\n",
        "label_dict_coco = label_map_util.get_label_map_dict(label_map_coco_path, use_display_name=True)\n",
        "label_dict_coco = {k.lower():v for k, v in label_dict_coco.items()}\n",
        "#print(label_dict_coco)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KuCNip7nVa9"
      },
      "source": [
        "classes = list(filter(None, classes_set2))\n",
        "classes = {name.lower(): idx + 1 for idx, name in enumerate(classes)}\n",
        "print(classes)\n",
        "\n",
        "def rearrange_class_idx(class_dict, dataset_dict, class_list):\n",
        "  for idx, class_id in enumerate(class_list):\n",
        "    #print(class_id)\n",
        "    class_name = list(dataset_dict.keys())[list(dataset_dict.values()).index(class_id)]\n",
        "    #print(class_name)\n",
        "    class_list[idx] = class_dict[class_name]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfSmDpO-WsR7"
      },
      "source": [
        "#@title make directories { display-mode: \"form\" }\n",
        "\n",
        "# make directories\n",
        "make_dir(fail_dir)\n",
        "make_dir(tf_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzlWxWbLfjAe"
      },
      "source": [
        "#@title Run compare! { display-mode: \"form\" }\n",
        "print(\"Start filtering training set...\")\n",
        "run_filter_on_dir2(image_dir_train, annotation_path_train)\n",
        "print(\"Done!\")\n",
        "print(\"Start filtering validation set...\")\n",
        "run_filter_on_dir2(image_dir_val, annotation_path_val)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uazJ5ASc2_QE"
      },
      "source": [
        "#@title Modify config file { display-mode: \"form\" }\n",
        "\n",
        "import re\n",
        "\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "dst_ppl = os.path.join('/content/', pipeline_file)\n",
        "copyfile(pipeline_fname, dst_ppl)\n",
        "\n",
        "DEST_DIR = os.path.join('/content/', MODEL_NAME_TRAIN)\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "\n",
        "label_map_int = label_map_util.load_labelmap(dst_label)\n",
        "num_classes = label_map_util.get_max_label_map_index(label_map_int)\n",
        "\n",
        "num_image = len(os.listdir(image_dir_val)) -1\n",
        "print(num_classes)\n",
        "\n",
        "\n",
        "with open(dst_ppl) as f:\n",
        "    s = f.read()\n",
        "with open(dst_ppl, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(dst_label), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Set validating image number\n",
        "    s = re.sub('num_examples: [0-9]+',\n",
        "               'num_examples: {}'.format(num_image), s)\n",
        "\n",
        "    if load_all_ckpt == True:\n",
        "        s = re.sub('fine_tune_checkpoint_type:  \"detection\"\\n', \n",
        "                   'fine_tune_checkpoint_type:  \"detection\"\\n  load_all_detection_checkpoint_vars: true\\n', s)\n",
        "\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kELxMkzMfkop"
      },
      "source": [
        "## Make tf record files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH1UZvFnjDqA"
      },
      "source": [
        "#write in class file\n",
        "with open(class_dir, \"w\") as file:\n",
        "  file.writelines([\"%s\\n\" % item  for item in classes_set2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzi0MdRFNPj7"
      },
      "source": [
        "output_file='/content/tfrecord/train.tfrecord'\n",
        "classes_file = class_dir\n",
        "class_descriptions_file = class_description_path\n",
        "annotations_file = annotation_path_train\n",
        "image_dir = image_dir_train\n",
        "\n",
        "write_tf(classes_file, output_file, class_descriptions_file, annotations_file, image_dir)\n",
        "\n",
        "output_file='/content/tfrecord/val.tfrecord'\n",
        "classes_file = class_dir\n",
        "class_descriptions_file = class_description_path\n",
        "annotations_file = annotation_path_val\n",
        "image_dir = image_dir_val\n",
        "\n",
        "write_tf(classes_file, output_file, class_descriptions_file, annotations_file, image_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27vjgyGZvC1m"
      },
      "source": [
        "##download pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPNwTKEfal2I"
      },
      "source": [
        "#%cd /content/\n",
        "\n",
        "#!wget http://download.tensorflow.org/models/object_detection/${MODEL_NAME_TRAIN}.tar.gz\n",
        "#!tar -xzvf ${MODEL_NAME_TRAIN}.tar.gz\n",
        "\n",
        "MODEL_FILE = MODEL_NAME_TRAIN + '.tar.gz'\n",
        "print(DOWNLOAD_BASE + MODEL_FILE)\n",
        "%cd /content/\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j26-rcR-PHMj"
      },
      "source": [
        "\n",
        "!cat $dst_ppl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRkJZrr_0DGm"
      },
      "source": [
        "##train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV4Y3iAOV0EW"
      },
      "source": [
        "%cd /content\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8qyysVQ6Qih"
      },
      "source": [
        "%cd /content/models/research\n",
        "!export PYTHONPATH=$PYTHONPATH:/content/models/research:/content/models/research/slim\n",
        "!rm -rf $MODEL_DIR\n",
        "!mkdir $MODEL_DIR\n",
        "!python3 /content/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=$dst_ppl \\\n",
        "    --model_dir=$MODEL_DIR \\\n",
        "    --num_train_steps=$TRAIN_STEP \\\n",
        "    --num_eval_steps=$EVAL_STEP \\\n",
        "    --alsologtostderr \\\n",
        "    --sample_1_of_n_eval_examples=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!rm -rf $output_freeze_directory\n",
        "!mkdir $output_freeze_directory\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=$dst_ppl \\\n",
        "    --output_directory=$output_freeze_directory \\\n",
        "    --trained_checkpoint_prefix=$last_model_path \\\n",
        "    --run_once"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD"
      },
      "source": [
        "!ls {output_freeze_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFSn-5uidgtt"
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_freeze_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhIWks7yT7C"
      },
      "source": [
        "print(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvqGc-CI3u6U"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}